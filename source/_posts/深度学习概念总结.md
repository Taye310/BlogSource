---
title: 深度学习概念总结
date: 2019-03-25 21:54:50
tags:
    - 深度学习
    - 基础知识
categories: 学习笔记
---

encoder-decoder类型网络  
autoencoder & PCA (Principal component analysis)所引发的对监督/非监督学习更深入的思考：  

[batch normalization](https://morvanzhou.github.io/tutorials/machine-learning/torch/5-04-A-batch-normalization/):当然我们是可以用之前提到的对数据做 normalization 预处理, 使得输入的 x 变化范围不会太大, 让输入值经过激励函数的敏感部分. 但刚刚这个不敏感问题不仅仅发生在神经网络的输入层, 而且在隐藏层中也经常会发生。  
神经网络的输入参数维度越低越好

图卷积神经网络[资料](http://tkipf.github.io/graph-convolutional-networks/)
非欧空间数据如何处理

vgg16:Conv5_3指的是第五个卷积block里面的第三个卷积层
图卷积神经网络：[eng](http://tkipf.github.io/graph-convolutional-networks/)
处理非欧空间数据

聚类算法：[四种](https://blog.csdn.net/u011511601/article/details/81951939)

Drawing 3D (or 2D) shapes differentiably is challenging in TensorFlow
DIRT(git)解决了可以解决这个问题


查看cuda版本：cat /usr/local/cuda/version.txt
查看cudnn版本：cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2