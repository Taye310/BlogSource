---
title: 关于三维重建的文献综述
date: 2019-01-04 07:58:17
tags: 
    - 3D model reconstruction
    - 文献综述
categories: 论文综述
---

# 目录

[arXiv检索](https://arxiv.org/)

1. 1812.10558 通过视频素材实现从2d到3d的面部重建来完成测谎
2. 1812.01742 单一视角的三维重建，使用对抗训练（非人
3. 1812.05583 基于学习的ICP（迭代最近点算法）重构场景（非人
4. 1812.07603 通过视频素材的面部模型学习
5. 1812.05806 自我监督的引导方法，单图片的三维人脸重建
6. 1812.02822 学习生成模型的隐藏区域（非人
7. 1901.00049 基于轮廓的衣着人物（全身

**A类**

* 通过直接体积cnn回归从单图重建大范围三维人脸（源码lua+py
* 使用图到图转换的无限制面部重建（源码lua

**老师推荐**

* 使用affinity field的实时多人二维姿态估计

# 综述

## 通用

**关于三维重建**  
单个图像进行三维重建的数据驱动方法：一是明确使用三维结构，二是使用其他信息推断三维结构  
2DImage-->encoder-->latent representation-->decoder-->3DObject  
不同方法区别在于对三维世界采取的**限制**：多视图一致性学习三维表示、利用关键点和轮廓注释、利用2.5D草图（法线，深度和轮廓）改善预测  

encoder-decoder的[含义](https://blog.csdn.net/chinabing/article/details/78763454)

**关于shape priors**
许多方法选择更好的捕捉多样的真实形状  
**non-deep方法**关注低维参数模型，使用CNN来学习2D渲染图像和3D形状的**共同嵌入空间**  
其他方法依赖**生成模型**去学习shape priors

## 博客链接

[3D人脸重建学习笔记CSDN](https://blog.csdn.net/yyyllla/article/details/84573393)  
[3D重建的学习笔记简书](https://www.jianshu.com/p/f33b3d440f7d)

## ID:1812.01742  

传统方法用多个角度的多张照片实现三维建模  
问题两个：一是需要大量的观察点；二是物体表面是*Lambertian*（非反射）albedos是非均匀的  
另一种三维重建的方式是利用物体外观和形状的知识从单视图二维图像生成（假设shape priors足够丰富）  
CAD库（computer-aided design）：<u>shapenet，pascal3d+，objectnet3d，pix3d</u>  

这些方法都从渲染的图像中回归三维形状：将二位图像转化成潜在表示的**编码器** 以及 重建三维表示的**解码器**  
为了学习shape priors深度学习算法需要大量的三维对象注释，自然图像中获取三维注释很有挑战，因此使用合成图像（三维模型渲染出的图像）  
CNN的<u>domain shift</u>问题，导致基于cnn的三维重建性能恶化  

这篇文章的方法：提高重建模型性能，为了实现获取三维物体标签，他们shape priors训练出的网络有个**重建损失值**，给这个值引入了两个限制  
一是受domain shift文献启示，强制让编码的二维特征不变，对应于他们所来自的domain。这样合成图像训练出的编码器在真实图像上表现更好  
二是将编码的二维特征限制在现实物体的多种形状之中，通过对抗训练定义这两个损失值  
总结：一个**模型**和**损失函数**，利用shape priors提高自然图像三维重建性能（两种方式使用对抗训练）  
reconstruction adversarial network(RAN)  
**只使用rgb图像信息**，和易于获取的自然图像。独立于编码器和解码器，并且可以使用到其中  
借鉴了domain confusion（作用是classification），为了让从合成图像里训练出来的模型在真实图像这边有更好的表现  

具体方法：todo

## 通过直接体积cnn回归从单图重建大范围三维人脸

目前三维人脸重建的方法多假定有多张面部图片可以使用，这使得重建面临方法上的挑战：在夸张的表情、不均匀光照上建立稠密对应关系  
这些方法需要复杂低效的管道构建模型，拟合模型。本文建议通过在由2D图像和3D面部模型或扫描组成的适当数据集上训练卷积神经网络
（CNN）来解决这些限制

## 极端3D面部重建：遮挡透视（讲）

bumpingmapping概念的推动下，该文提出了一种分层方法。将全局形状与其中细节进行解耦。估计粗糙的3d面部形状为基础，然后将此基础与凹凸贴图表示的细节分开。
与本文相关的工作：
    reconstruction by example 这类方法用三维脸部形状去调整根据输入图片估计出的模型，降低了观看条件却损失了真实度与准确性  
    face shape from facial landmarks 这类方法稳定但是模型都差不多，没有细节，而且不清楚遮挡landmark的情况下表现会如何  
    SfS *Shape-From-shading* 根据光反射生成细节丰富的模型，但是受环境影响严重，需要满足其对环境的特殊要求。任何遮挡物都会生成到模型中  
    statistical representations 最著名的方法是3DMM，这篇文改进了这个方法直接根据图片强度信息用cnn回归3DMM的参数和面部细节  
    deep face shape estimation 深度网络一是直接用深度图重建，二是estimate 3D shapes with anemphasis on unconstrained photo 观察条件高度不变但是细节模糊  

**准备工作**  
矛盾：整体形状的高度正则化vs细节的弱正则化。解决方法：bump map representations which separate global shape from local details
    理解的正则化：使模型更有普适性，低正则化是让模型有更多细节、更有特点，反之是让模型更接近普适的规则（每个模型都有一只鼻子一张嘴两只眼睛）
给一张图片建立以下几个部分：基础形状——S，面部表情——E，6维度的自由视点——V。接下来是bump map捕捉中级特征（皱纹等非参数的），最后完成因遮挡丢失的细节。  
**添加细节**
基础形状使用3DMM，3DMM用了resnet的101层网络架构。表情部分由3DDFA提供，更新的有expnet。确定视点用了deep，facepostnet。  
中等程度细节：image to bump map，修复遮挡细节，基于软对称的模型完善。  
[LFW验证](http://vis-www.cs.umass.edu/lfw/)

PPT用：
目的：现有单图三维重建局限性很高，必须在正前方、距离近、无阻挡的视点，该文设计了一种用于在极端条件下提供细节丰富的面部三维重建模型的系统。极端条件包括，头部旋转以及遮挡
方法：简单讲步骤，关键的创新点，值得学习的点后边会细说。
总的来说：先创建面部整体的基础形状，与局部细节分开，在基础形状之上建立中等程度的面部特征。这样做可以保证极端条件下整体面部形状的稳定性。其他较新的方法往往用局部细节构建整体形状。
 构建基础形状s，构建面部表情e，构建视点v：*凹凸图可以分离整体形状和局部细节*
这仨东西分别是干什么用的：*基础形状使用3DMM，3DMM用了resnet的101层网络架构。表情部分由3DDFA提供，更新的有expnet。确定视点用了deep，facepostnet。*
image to bump map转换
凹凸图训练集：用深度编码-解码框架生成凹凸图
学习建立凹凸图：定义了自己的网络损失函数，可以在不牺牲高频细节的情况下抑制噪声
还原遮挡细节
给予范例的空洞填充方法
搜索参考集
混合细节
更复杂的修补
基于软对称的模型补全  

贡献：解决**对foundation的高度正则化** VS **对detail的低正则化** 两者的矛盾  

注：  
    bump map使用灰度值来提供高度信息，normal map使用xyz轴所对应的rgb信息
    [卷积与反卷积](https://github.com/vdumoulin/conv_arithmetic)

跑demo流程：
    NVIDIA-docker启动container，如果跑代码没有driver重新run一个，用readme里的run命令。
    之后会出现860m只支持cuda5.0的报错，需要[从源码编译pytorch](https://github.com/pytorch/pytorch#from-source)。首先docker里装anaconda
        wget https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/Anaconda3-2018.12-Linux-x86_64.sh
        应该不用在docker里装cuda和cudnn，直接安装pytorch的依赖然后安装pytorch应该就可以  
        在1080上不会出现上边的报错，完全按照README走就行。

[PPT](extreme_3d_face.pptx)

<iframe src='https://view.officeapps.live.com/op/view.aspx?src=https://taye310.github.io/2019/01/04/%E5%85%B3%E4%BA%8E%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA%E7%9A%84%E6%96%87%E7%8C%AE%E7%BB%BC%E8%BF%B0/extreme_3d_face.pptx' width=800 height=600 frameborder='1'></iframe>

## Learning to Estimate 3D Human Pose and Shape from a Single Color Image(讲)

SCAPE:  shape  completion  and  animationof people
SMPL: A skinned multi-person linear model  
SMPL是一种参数化人体模型，与非参数化模型的区别在于，参数化的可以用函数映射的方式表达出来，或者说是可以解析的？非参数化则认为是通过实验记录到的模型，不存在解析表达式。  


Stacked Hourglass Networks[一](https://blog.csdn.net/wangzi371312/article/details/81174452)[二](https://blog.csdn.net/shenxiaolu1984/article/details/51428392)

{% asset_img lv2glasshour.jpg 二级沙漏 %}

{% asset_img human3d.png 文中所用沙漏模型 %}

[feature map:](https://blog.csdn.net/dengheCSDN/article/details/77848246)
channel:
卷积核个数、特征图个数、通道个数关系

[PPT](Learning to Estimate 3D Human Pose and Shape from a Single Color Image.pptx)

<iframe src='https://view.officeapps.live.com/op/view.aspx?src=https://taye310.github.io/2019/01/04/%E5%85%B3%E4%BA%8E%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA%E7%9A%84%E6%96%87%E7%8C%AE%E7%BB%BC%E8%BF%B0/Learning to Estimate 3D Human Pose and Shape from a Single Color Image.pptx' width=800 height=600 frameborder='1'></iframe>

## O-CNN: Octree-based Convolutional Neural Networks for 3D Shape Analysis

还有adaptive o-cnn  
The main technical challenge of the O-CNN is to parallelize the O-CNN computations defined on the sparse octants so that they can be efficiently executed on the GPU  
We train this O-CNN model with 3D shape datasets and refine the O-CNN models with different back-ends for three shape analysis tasks, including object classification, shape retrieval, and shape segmentation.

## Pixel2Mesh（讲）

### code

编译tensorflow math_functions.hpp找不到。需要软链接这个玩意  
ln -s /usr/local/cuda/include/crt/math_functions.hpp /usr/local/cuda/include/math_functions.hpp  

关于eigen和cuda[资料](https://blog.csdn.net/O1_1O/article/details/80066236)  
makefile怎么写。  
hdf5 HDF（Hierarchical Data Format）是一种设计用于存储和组织大量数据的文件格式

__CUDACC_VER__ is no longer supported.的报错看来要更新[eigen3](https://blog.csdn.net/luojie140/article/details/80159227)才能解决
github上新版eigen考到anaconda的eigen和support里就可以成功编译cuda了

图卷积神经网络[资料](http://tkipf.github.io/graph-convolutional-networks/)




fusion
multy domin
多元融合